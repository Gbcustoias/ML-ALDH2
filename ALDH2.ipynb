{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Projeto predição de mutação gene ALDH2**\n",
    "\n",
    "O seguinte projeto foi realizado anteriormente com dados reais obtidos a partir do projeto de pesquisa de doutorado da medicina/USP. Para manter a integridade e proteção dos daods da pesquisa, foram utilizados dados fictícios nesta análise.\n",
    "\n",
    "**Importância da predição de indivíduos com mutação no gene ALDH2:**\n",
    "A enzima mitocondrial ALDH2 desempenha um papel fundamental na metabolização do etanol. A presença de uma mutação genética no gene responsável por essa enzima resulta em uma diminuição de sua atividade enzimática, levando a um comprometimento do processo metabólico. Dadas as consideráveis despesas associadas à realização de análises de confirmação desta mutação, a adoção de abordagens de predição utilizando machine learning emerge como uma alternativa viável tanto para fins terapêuticos quanto para o avanço de\n",
    "investigações futuras.\n",
    "\n",
    "**Variáveis utilizadas e desfecho**\n",
    "O desfecho utilizado foi a classificação de existência ou não de mutação no gene ALDH2. Para isso foram utilizados variáveis possivelmente preditoras de mutação do gene, sendo elas:\n",
    "- Indíce de massa corporal (IMC)\n",
    "- Percentual de massa magra\n",
    "- Percentual de massa gorda\n",
    "- Testes de força isométrica pré e pós dano muscular induzido por treino de força (MVIC 1-5)\n",
    "- Teste de força máxima no leg-press (1RM leg-press)\n",
    "- Frequência cardíaca pré, 30 e 60 minutos pós ingestão de álcool (FC)\n",
    "- Pressão arterial sistólica pré, 30 e 60 minutos pós ingestão de álcool (PAS)\n",
    "- Pressão arterial diastólica pré, 30 e 60 minutos pós ingestão de álcool\n",
    "Etapas de Análise (PAD)\n",
    "- Escala de dor muscular pós dano muscular induzido por treino de força 24 e 48h\n",
    "- Autoavaliação de rubor para a pergunta \"Você geralmente tem a tendência de ficar com a pele do resto vermelha imediatamente após o consumo de alguma dose de álcool?\"\n",
    "- Autoavaliação de rubor para a pergunta \"Você geralmente tem a tendência de ficar com a pele do resto vermelha imediatamente após o seu primeiro ou segundo ano em que começou a consumir álcool?\"\n",
    "- Visualização de rubor após ingestão de álcool\n",
    "\n",
    "**Roteiro:**\n",
    "\n",
    "1. Instalação dos pacotes recomendados\n",
    "\n",
    "2. Importando pacotes e denominando-os\n",
    "\n",
    "3. Selecionando e verificando o banco de dados\n",
    "\n",
    "4. Filtando banco de dados\n",
    "  \n",
    "  4.1 Transformando variáveis categóricas em label enconding/one-hot enconding\n",
    "  \n",
    "  4.2 Padronização variáveis quantitativas\n",
    "\n",
    "5. Random Forest\n",
    "\n",
    "  5.1 Random forest com hiperparâmetros\n",
    "\n",
    "6. XGBOOST\n",
    "\n",
    "  6.1 XGBOOST com hiperparâmetros\n",
    "\n",
    "7. CATBOOST\n",
    "\n",
    "  7.1 CATBOOST com hiperparâmetros\n",
    "\n",
    "8. Variáveis selecionadas pelo algoritmo\n",
    "\n",
    "  8.1 BORUTA\n",
    "\n",
    "  8.2 Shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Instação dos pacotes recomendados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dfply >> /dev/null\n",
    "!pip install xgboost >> /dev/null\n",
    "!pip install boruta >> /dev/null\n",
    "!pip install shap >> /dev/null\n",
    "!pip install catboost >> /dev/null\n",
    "!pip install --upgrade shap >> /dev/null\n",
    "!pip install scikit-plot >> dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Importando pacotes e denominando-os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação dos pacotes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from dfply import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "np.random.seed(42)  # semente de aleatoriedade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Selecionando e verificando o banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Puxando o banco de dados\n",
    "dataset = pd.read_excel ('https://drive.google.com/uc?export=download&id=1EgMqXPBioazgSim1m8D7Dk6D2f1_bBCv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info() #Obsevando o tipo das variáveis parametrizadas na chamada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Filtando banco de dados\n",
    "\n",
    "Removendo as variáveis que poderiam ser vazamento de dados ou desnecessárias.\n",
    "\n",
    "ID do voluntário\n",
    "Idade\n",
    "Massa e estatura (deixando apenas o IMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALDH2data = (dataset >>\n",
    "            drop(X.ID, X.Idade, X.Massa, X.Estatura))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Imputando missing data\n",
    "\n",
    "Nos missing data de variáveis quantitativas foi utilizado a média e nas variáveis categóricas a moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALDH2data.describe().T #Observando dados estatísticos básicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de nomes das colunas quantitativas e categóricas\n",
    "col_quant = ['IMC', 'Massa Magra', 'Massa Gorda', '1 Teste MVIC', '2 Teste MVIC', '3 Teste MVIC', '4 Teste MVIC', '5 Teste MVIC', '1RM leg-press', 'FC pré', 'FC 30 min', 'FC 60 min', 'PAS pré', 'PAS 30 min', 'PAS 60 min', 'PAD pré', 'PAD 30 min', 'PAD 60 min', 'Escala de Dor 24h', 'Escala de Dor 48h']\n",
    "col_cat = ['Mutação', 'Autoavaliação rubor atual', 'Autoavaliação rubor inicial','Visualiação rubor']\n",
    "\n",
    "#Dataframe separado para cada tipo de variável\n",
    "ALDH2quant = ALDH2data[col_quant]\n",
    "ALDH2cat = ALDH2data[col_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputando a média nas variáveis quantitativas\n",
    "imputerquant = SimpleImputer(strategy='mean')\n",
    "imputerquant.fit(ALDH2quant)\n",
    "ALDH2data_quant = imputerquant.transform(ALDH2quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputando a moda nas variáveis categóricas\n",
    "imputercat = SimpleImputer(strategy='most_frequent')\n",
    "imputercat.fit(ALDH2cat)\n",
    "ALDH2data_cat = imputercat.transform(ALDH2cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando os arrays NumPy em dataframes\n",
    "ALDH2data_quant = pd.DataFrame(ALDH2data_quant, columns=ALDH2quant.columns)\n",
    "ALDH2data_cat = pd.DataFrame(ALDH2data_cat, columns=ALDH2cat.columns)\n",
    "\n",
    "#Juntando os dataframes quantitativos e categóricos ao longo das colunas (axis=1)\n",
    "dfALDH2 = pd.concat([ALDH2data_quant, ALDH2data_cat], axis=1)\n",
    "\n",
    "#Observando se foi imputado os valores missing\n",
    "dfALDH2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Transformando variáveis categóricas em label enconding\n",
    "\n",
    "Não foi necessário one-hot encoding, pois todas as varíaveis categóricas só possuiam 2 categórias após imput dos missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label enconding\n",
    "dfALDH2[['Mutação','Autoavaliação rubor atual', 'Autoavaliação rubor inicial', 'Visualiação rubor']] = dfALDH2[['Mutação', 'Autoavaliação rubor atual', 'Autoavaliação rubor inicial', 'Visualiação rubor']].apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfALDH2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Padronização variáveis quantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas com dados quantitativos\n",
    "var_quant = dfALDH2.select_dtypes(include=['float64']).columns\n",
    "\n",
    "#Padronização das variáveis quantitativas\n",
    "scaler = StandardScaler()\n",
    "dfALDH2[var_quant] = scaler.fit_transform(dfALDH2[var_quant])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Random Forest\n",
    "\n",
    "Por conta do n amostral ser baixo foi realizado uma cross-validation direta, sem realização da separação entre treino e teste. O número de folds foi definido pelo n amostral ser =24, onde ambos os grupos (desfecho posítivo ou negativo) eram multiplos de 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo as variáveis independentes e a variável dependente\n",
    "X = dfALDH2.drop(columns=['Mutação'])\n",
    "y = dfALDH2['Mutação'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o número de folds\n",
    "n_folds = 3\n",
    "\n",
    "#Objeto de validação cruzada com 3 folds\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Realizando a validação cruzada e calculando as métricas\n",
    "cross_val_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "cross_val_auc_scores = cross_val_score(model, X, y, cv=kf, scoring='roc_auc')\n",
    "cross_val_precision_scores = cross_val_score(model, X, y, cv=kf, scoring='precision')\n",
    "cross_val_recall_scores = cross_val_score(model, X, y, cv=kf, scoring='recall')\n",
    "\n",
    "#Pontuações de validação cruzada para cada fold\n",
    "for i, (accuracy, auc, precision, recall) in enumerate(zip(cross_val_scores, cross_val_auc_scores, cross_val_precision_scores, cross_val_recall_scores)):\n",
    "    print(f'Fold {i + 1} - Acurácia: {accuracy:.4f}, AUC: {auc:.4f}, Precisão: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "#Calculando as métricas médias em todos os folds\n",
    "mean_accuracy = cross_val_scores.mean()\n",
    "mean_auc = cross_val_auc_scores.mean()\n",
    "mean_precision = cross_val_precision_scores.mean()\n",
    "mean_recall = cross_val_recall_scores.mean()\n",
    "\n",
    "print('Random Forest')\n",
    "print(f'Acurácia Média: {mean_accuracy:.4f}')\n",
    "print(f'AUC Médio: {mean_auc:.4f}')\n",
    "print(f'Precisão Média: {mean_precision:.4f}')\n",
    "print(f'Recall Médio: {mean_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo a grade de hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 20],\n",
    "    'max_depth': [3, 4, 5, None],\n",
    "    'min_samples_split':[4, 5, 6],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "#Criando o modelo Random Forest\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Criando o objeto de validação cruzada com 3 folds\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Criando o objeto GridSearchCV com scoring='roc_auc'\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "\n",
    "#Realizando o grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "#Obtendo os melhores hiperparâmetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "best_auc = grid_search.best_score_\n",
    "\n",
    "# Imprimindo os melhores hiperparâmetros e o AUC correspondente\n",
    "print(\"Melhores Hiperparâmetros:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Random Forest com os melhores hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os melhores hiperparâmetros\n",
    "best_params = {'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 20}\n",
    "\n",
    "# Definindo o número de folds\n",
    "n_folds = 3\n",
    "\n",
    "# Criando o modelo Random Forest com os melhores hiperparâmetros\n",
    "model = RandomForestClassifier(random_state=42, **best_params)\n",
    "\n",
    "#Objeto de validação cruzada com 3 folds\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Realizando a validação cruzada e calculando as métricas\n",
    "cross_val_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "cross_val_auc_scores = cross_val_score(model, X, y, cv=kf, scoring='roc_auc')\n",
    "cross_val_precision_scores = cross_val_score(model, X, y, cv=kf, scoring='precision')\n",
    "cross_val_recall_scores = cross_val_score(model, X, y, cv=kf, scoring='recall')\n",
    "\n",
    "#Pontuações de validação cruzada para cada fold\n",
    "for i, (accuracy, auc, precision, recall) in enumerate(zip(cross_val_scores, cross_val_auc_scores, cross_val_precision_scores, cross_val_recall_scores)):\n",
    "    print(f'Fold {i + 1} - Acurácia: {accuracy:.4f}, AUC: {auc:.4f}, Precisão: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "#Calculando as métricas médias em todos os folds\n",
    "mean_accuracy = cross_val_scores.mean()\n",
    "mean_auc = cross_val_auc_scores.mean()\n",
    "mean_precision = cross_val_precision_scores.mean()\n",
    "mean_recall = cross_val_recall_scores.mean()\n",
    "\n",
    "# Imprimindo as métricas médias\n",
    "print('Random Forest ajustado')\n",
    "print(f'Acurácia Média: {mean_accuracy:.4f}')\n",
    "print(f'AUC Médio: {mean_auc:.4f}')\n",
    "print(f'Precisão Média: {mean_precision:.4f}')\n",
    "print(f'Recall Médio: {mean_recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo as variáveis independentes e a variável dependente\n",
    "X = dfALDH2.drop(columns=['Mutação'])\n",
    "y = dfALDH2['Mutação'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o modelo XGBoost\n",
    "model = make_pipeline(StandardScaler(), XGBClassifier(random_state=42, objective='binary:logistic', use_label_encoder=False))\n",
    "\n",
    "#Definindo o número de folds\n",
    "n_folds = 3\n",
    "\n",
    "#Objeto de validação cruzada com 3 folds\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Realizando a validação cruzada e calculando as métricas\n",
    "cross_val_accuracies = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "cross_val_auc_scores = cross_val_score(model, X, y, cv=kf, scoring='roc_auc')\n",
    "cross_val_precision_scores = cross_val_score(model, X, y, cv=kf, scoring='precision')\n",
    "cross_val_recall_scores = cross_val_score(model, X, y, cv=kf, scoring='recall')\n",
    "\n",
    "#Pontuações de validação cruzada para cada fold\n",
    "for i, (accuracy, auc, precision, recall) in enumerate(zip(cross_val_accuracies, cross_val_auc_scores, cross_val_precision_scores, cross_val_recall_scores)):\n",
    "    print(f'Fold {i + 1} - Acurácia: {accuracy:.4f}, AUC: {auc:.4f}, Precisão: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "#Calculando as métricas médias em todos os folds\n",
    "mean_accuracy = cross_val_accuracies.mean()\n",
    "mean_auc = cross_val_auc_scores.mean()\n",
    "mean_precision = cross_val_precision_scores.mean()\n",
    "mean_recall = cross_val_recall_scores.mean()\n",
    "\n",
    "print('XGBOOST')\n",
    "print(f'Acurácia Média: {mean_accuracy:.4f}')\n",
    "print(f'AUC Médio: {mean_auc:.4f}')\n",
    "print(f'Precisão Média: {mean_precision:.4f}')\n",
    "print(f'Recall Médio: {mean_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo lista de hiperparâmetros a serem otimizados\n",
    "param_grid = {\n",
    "    'xgbclassifier__n_estimators': [5, 10, 20],\n",
    "    'xgbclassifier__max_depth': [3, 4, 5],\n",
    "    'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgbclassifier__subsample': [0.8, 1.0],\n",
    "    'xgbclassifier__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "#Criando o objeto de validação cruzada com 3 folds\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Criando o objeto GridSearchCV com scoring='roc_auc'\n",
    "grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "\n",
    "#Realizando o grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "#Obtendo os melhores hiperparâmetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "best_auc = grid_search.best_score_\n",
    "\n",
    "#Imprimindo os melhores hiperparâmetros e o AUC correspondente\n",
    "print(\"Melhores Hiperparâmetros:\")\n",
    "print(best_params)\n",
    "print(f'Melhor AUC: {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 XGBOOST com melhores hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective='binary:logistic',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "#Definindo o número de folds\n",
    "n_folds = 3\n",
    "\n",
    "#Realizando a validação cruzada e calculando as métricas\n",
    "cross_val_auc_scores = cross_val_score(best_xgb_model, X, y, cv=kf, scoring='roc_auc')\n",
    "cross_val_accuracy_scores = cross_val_score(best_xgb_model, X, y, cv=kf#Criando o modelo XGBoost com os melhores hiperparâmetros\n",
    "best_xgb_model = XGBClassifier(\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=20,\n",
    "    subsample=1.0,\n",
    "    random_state=42,, scoring='accuracy')\n",
    "cross_val_precision_scores = cross_val_score(best_xgb_model, X, y, cv=kf, scoring='precision')\n",
    "cross_val_recall_scores = cross_val_score(best_xgb_model, X, y, cv=kf, scoring='recall')\n",
    "\n",
    "#Pontuações de validação cruzada para cada fold\n",
    "for i, (auc, accuracy, precision, recall) in enumerate(zip(cross_val_auc_scores, cross_val_accuracy_scores, cross_val_precision_scores, cross_val_recall_scores)):\n",
    "    print(f'Fold {i + 1} - AUC: {auc:.4f}, Acurácia: {accuracy:.4f}, Precisão: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "#Calculando as métricas médias em todos os folds\n",
    "mean_auc = cross_val_auc_scores.mean()\n",
    "mean_accuracy = cross_val_accuracy_scores.mean()\n",
    "mean_precision = cross_val_precision_scores.mean()\n",
    "mean_recall = cross_val_recall_scores.mean()\n",
    "\n",
    "#Imprimindo as métricas médias\n",
    "print('XGBOOST ajustado')\n",
    "print(f'AUC Médio: {mean_auc:.4f}')\n",
    "print(f'Acurácia Média: {mean_accuracy:.4f}')\n",
    "print(f'Precisão Média: {mean_precision:.4f}')\n",
    "print(f'Recall Médio: {mean_recall:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo as variáveis independentes e a variável dependente\n",
    "X = dfALDH2.drop(columns=['Mutação'])\n",
    "y = dfALDH2['Mutação'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o modelo CatBoost\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=False)\n",
    "\n",
    "#Definindo o número de folds\n",
    "n_folds = 3\n",
    "\n",
    "#Realizando a validação cruzada e calculando as métricas\n",
    "cross_val_auc_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='roc_auc')\n",
    "cross_val_accuracy_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='accuracy')\n",
    "cross_val_precision_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='precision')\n",
    "cross_val_recall_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='recall')\n",
    "\n",
    "#Pontuações de validação cruzada para cada fold\n",
    "for i, (auc, accuracy, precision, recall) in enumerate(zip(cross_val_auc_scores, cross_val_accuracy_scores, cross_val_precision_scores, cross_val_recall_scores)):\n",
    "    print(f'Fold {i + 1} - AUC: {auc:.4f}, Acurácia: {accuracy:.4f}, Precisão: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "#Calculando as métricas médias em todos os folds\n",
    "mean_auc = cross_val_auc_scores.mean()\n",
    "mean_accuracy = cross_val_accuracy_scores.mean()\n",
    "mean_precision = cross_val_precision_scores.mean()\n",
    "mean_recall = cross_val_recall_scores.mean()\n",
    "\n",
    "#Imprimindo as métricas médias\n",
    "print('CATBOOST')\n",
    "print(f'AUC Médio: {mean_auc:.4f}')\n",
    "print(f'Acurácia Média: {mean_accuracy:.4f}')\n",
    "print(f'Precisão Média: {mean_precision:.4f}')\n",
    "print(f'Recall Médio: {mean_recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo lista de hiperparâmetros a serem otimizados\n",
    "param_grid_catboost = {\n",
    "    'iterations': [5, 10, 20],\n",
    "    'depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bylevel': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "#Criando o modelo CatBoost\n",
    "catboost_model = CatBoostClassifier(random_state=42, verbose=False)\n",
    "\n",
    "#Criando o objeto GridSearchCV com scoring='roc_auc'\n",
    "grid_search_catboost = GridSearchCV(catboost_model, param_grid_catboost, cv=kf, scoring='roc_auc', verbose=1, n_jobs=-1)\n",
    "\n",
    "#Realizando o grid search\n",
    "grid_search_catboost.fit(X, y)\n",
    "\n",
    "#Melhores hiperparâmetros encontrados\n",
    "best_params_catboost = grid_search_catboost.best_params_\n",
    "best_auc_catboost = grid_search_catboost.best_score_\n",
    "\n",
    "# Imprima os melhores hiperparâmetro\n",
    "print(\"Melhores Hiperparâmetros CatBoost:\")\n",
    "print(best_params_catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 CATBOOST com melhores hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo os hiperparâmetros\n",
    "catboost_params = {\n",
    "    'colsample_bylevel': 0.8,\n",
    "    'depth': 3,\n",
    "    'iterations': 5,\n",
    "    'learning_rate': 0.2,\n",
    "    'subsample': 1.0\n",
    "}\n",
    "\n",
    "#Criando o modelo CatBoost\n",
    "catboost_model = CatBoostClassifier(**catboost_params, random_state=42, verbose=False)\n",
    "\n",
    "#Definindo o número de folds\n",
    "n_folds = 3\n",
    "\n",
    "#Objeto de validação cruzada com 3 folds\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "#Realizando a validação cruzada e calculando as métricas\n",
    "cross_val_accuracy_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='accuracy')\n",
    "cross_val_auc_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='roc_auc')\n",
    "cross_val_precision_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='precision')\n",
    "cross_val_recall_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='recall')\n",
    "cross_val_f1_scores = cross_val_score(catboost_model, X, y, cv=kf, scoring='f1')\n",
    "\n",
    "#Pontuações de validação cruzada para cada fold\n",
    "for i, (accuracy, auc, precision, recall) in enumerate(zip(cross_val_accuracy_scores, cross_val_auc_scores, cross_val_precision_scores, cross_val_recall_scores)):\n",
    "    print(f'Fold {i + 1} - Acurácia: {accuracy:.4f}, AUC: {auc:.4f}, Precisão: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "#Calculando as métricas médias em todos os folds\n",
    "mean_accuracy = cross_val_accuracy_scores.mean()\n",
    "mean_auc = cross_val_auc_scores.mean()\n",
    "mean_precision = cross_val_precision_scores.mean()\n",
    "mean_recall = cross_val_recall_scores.mean()\n",
    "mean_f1 = cross_val_f1_scores.mean()\n",
    "\n",
    "#Imprimindo as métricas médias\n",
    "print(\"CATBOOST ajustado:\")\n",
    "print(f'Acurácia Média: {mean_accuracy:.4f}')\n",
    "print(f'AUC Médio: {mean_auc:.4f}')\n",
    "print(f'Precisão Média: {mean_precision:.4f}')\n",
    "print(f'Recall Médio: {mean_recall:.4f}')\n",
    "print(f'F1: {mean_f1:.4f}')\n",
    "\n",
    "runModel(catboost_model, X, y, title=\"Catboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Variáveis selecionadas pelo algoritmo\n",
    "\n",
    "Foi aplicado o BORUTA e SHAP para observar quais foram as principais variáveis utilizada pelo modelo para predição do desfecho pelo algoritmo CATBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 BORUTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiperparâmetros do CatBoost\n",
    "catboost_params = {'colsample_bylevel': 0.8, 'depth': 3, 'iterations': 5, 'learning_rate': 0.01, 'subsample': 0.8}\n",
    "\n",
    "#Modelo CatBoost\n",
    "catboost_model = CatBoostClassifier(**catboost_params)\n",
    "\n",
    "#Definindo as variáveis independentes e a variável dependente\n",
    "X = dfALDH2.drop(columns=['Mutação'])\n",
    "y = dfALDH2['Mutação'].values\n",
    "\n",
    "#Treinando o modelo CatBoost\n",
    "catboost_model.fit(X, y)\n",
    "\n",
    "#Importâncias das características do CatBoost\n",
    "feature_importances = catboost_model.feature_importances_\n",
    "\n",
    "#DataFrame com as importâncias das características\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "#Ordeneando as características por importância\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "#Selecionando as características com importância maior que zero\n",
    "selected_features = importance_df.loc[importance_df['Importance'] > 0, 'Feature'].tolist()\n",
    "\n",
    "# Imprima ou utilize as características selecionadas\n",
    "print(\"Características selecionadas pelo CatBoost:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo CatBoost\n",
    "catboost_model = CatBoostClassifier(**catboost_params)\n",
    "\n",
    "#Treinando o modelo CatBoost\n",
    "catboost_model.fit(X, y)\n",
    "\n",
    "#Aplicando o explainer SHAP\n",
    "explainer = shap.Explainer(catboost_model)\n",
    "\n",
    "#Obtendo os valores SHAP para todos os pontos de dados\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "#Resumo de plotagem para visualizar a importância das características\n",
    "shap.summary_plot(shap_values, X)\n",
    "\n",
    "# Criação do gráfico individual para pontos específicos\n",
    "shap.force_plot(explainer.expected_value, shap_values[0, :], X.iloc[0, :])\n",
    "\n",
    "# Inicializando o JavaScript para o SHAP\n",
    "shap.initjs()\n",
    "\n",
    "#Exibindo o force plot para um ponto específico\n",
    "shap.force_plot(explainer.expected_value, shap_values[i, :], X.iloc[i, :])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
